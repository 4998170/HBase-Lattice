#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass article
\begin_preamble
\renewcommand{\thefootnote}{\fnsymbol{footnote}}
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman lmodern
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder false
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle true
\papersize default
\use_geometry false
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation skip
\defskip medskip
\quotes_language english
\papercolumns 2
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
HBase Lattice Quick Start
\end_layout

\begin_layout Author
Dmitriy Lyubimov
\begin_inset Newline newline
\end_inset


\size small
\emph on
dlyubimov@apache.org
\end_layout

\begin_layout Section
What it is 
\end_layout

\begin_layout Standard
HBase Lattice is an attempt at BI solution.
 Namely, it is an attempt at building HBase-based incremental OLAP cube.
 
\end_layout

\begin_layout Standard
I scanned surroundings and noticed at least 2 such attempts which for various
 reasons (for most part, maturity and staleness) did not fit our purposes.
 
\end_layout

\begin_layout Standard
Like some MOLAP solutions, HBase-Lattice copes with aggregate queries by
 prebuilding certain cuboids in a cube lattice models.
 
\end_layout

\begin_layout Section
Motivations
\end_layout

\begin_layout Itemize

\series bold
In continuation of 
\begin_inset Quotes eld
\end_inset

Cassandra is OLTP, HBase is OLAP
\begin_inset Quotes erd
\end_inset

 mantra
\series default
.
 Except HBase is not really OLAP out of the door.
 It doesn't support cube models directly.
 There's no query language to use.
 There's no predefined way to update a cube.
 There're no concepts of dimension, hierarchy, measure and fact streams.
\end_layout

\begin_layout Itemize

\series bold
Big underlying fact stream
\series default
.
 (billions, perhaps trillions of facts to process) which we wont to cope
 with by parallelizing the compilation with the help of MapReduce.
 
\end_layout

\begin_layout Itemize

\series bold
Low query TTLB
\series default
 (especially on Time Series data).
 Our goal was to answer queries over any period of time and whatever other
 slice specifications we can make very quickly with a single hbase table
 and a very limited amount of iterations in a scan.
 (TTLB <~ 1ms on hbase side, assuming the tablet data is in memory, + whatever
 network overhead).
\end_layout

\begin_layout Itemize

\series bold
Next to realtime data availability for querying
\series default
.
 Use of incremental updates to cuboid projections in the lattice means there's
 no need to recompile the whole cube for the past 90 days or whatever.
 New fact data becomes available within single number of minutes after the
 fact actually happened, as soon as incremental compiler iteration is complete.
 Once compiled, the data remains continuously available unless thrown out
 by HBase during compaction given specified projection TTL parameter.
\end_layout

\begin_layout Itemize

\series bold
Keep stuff within same ecosystem.
 
\series default
Another motivation is being able to do things within the same resource space
 of HDFS and HBASE one already invested to.
 While it is definitely try to use other tools out there with same, if not
 greater, success, (MongoDB comes to mind), those tools would perhaps require
 their own distinct environment (resources) and perhaps bulk data transfer
 and import.
\end_layout

\begin_layout Section
Differentiating aspects of HBL vs.
 MOLAP, ROLAP and cube lattice model in general
\end_layout

\begin_layout Paragraph
No fact table, no facts kept around.
\end_layout

\begin_layout Standard
We don't keep individual facts around.
 Unlike perhaps with some other approaches, there's no level of indirection
 to query the fact table.
 All projection data is right there, in a cuboid table.
 This provides 2 major benefits: 
\end_layout

\begin_layout Itemize
Low query TTLBs.
 If we are hitting cuboid with precompiled aggregate results, we only need
 to scan a handful of items per request.
 
\end_layout

\begin_layout Itemize
Don't need the space to keep all original facts.
 Depending on the definition of dimensions and hierarchies and the nature
 of incoming fact streams, the space required to keep aggregated projections
 may require several orders of magnitude less space than the original fact
 stream.
\end_layout

\begin_layout Standard
The tradeoff is obviously in that one cannot query individual fact datum.
 It is assumed that facts are kept somewhere else outside HBL tables (and
 they usually are, so no need to mandate data duplication in HBL).
\end_layout

\begin_layout Paragraph
What cuboids are to be compiled is specified manually.
\end_layout

\begin_layout Standard
In the interest of keeping things simple, the model specification explicitly
 lists all cuboids to compile in the cube.
 Consequently, not all aggregated groups are avaialable for querying.
 Working out which cuboids to compile is similar to process where DBA tries
 to figure out which indices to deploy based on use patterns.
 
\end_layout

\begin_layout Standard
New projectsions can be added dynamically to the system.
 Just specify new projections, deploy the model and the compiler component
 will start producing new projections right away.
 (applying new projections over past data retroactively is not easy at this
 point though.
 Pretty much the only way to do that is to drop all existing data and re-compile
 all projections over the entire historical facts again).
\end_layout

\begin_layout Paragraph
Compiler is a Pig codegen.
\end_layout

\begin_layout Standard
The compiler component generates pig script at runtime based on current
 specification of the model.
 (see 
\emph on
sample
\emph default
 module for example how to run these scripts).
\end_layout

\begin_layout Standard
One of the somewhat stale projects on github used similar approach but instead
 of using Apache Pig, that project used python streaming MR.
 But the idea is very similar.
 
\end_layout

\begin_layout Paragraph
Querying the data.
\end_layout

\begin_layout Standard
Data querying is available in two ways: 
\end_layout

\begin_layout Itemize
an API query class (not unlike the declarative api way to construct query
 objects in Hibernate), and 
\end_layout

\begin_layout Itemize
a simplistic query language that translates into that api calls to setup
 a query from reporting tools (again, not unlike HQL support in Hibernate).
 
\end_layout

\begin_layout Standard
In either case, a special custom hbase filter is used to allow to skip over
 the rows we are not really interested in, so the scan iterations are kept
 going over mostly relevant facts only.
\end_layout

\begin_layout Section
Quick Howto
\end_layout

\begin_layout Subsection
Specifying a model.
\end_layout

\begin_layout Standard
Model is specified by composing a bunch of java classes representing cube,
 cuboids, hierarchies, dimensions and measures.
 Instead of writing some java code wiring this composition up, it is also
 to use a declarative approach for model definition.
 We use YAML for declarative model definition (see file 
\family typewriter
example.yaml
\family default
 in the 
\emph on
sample
\emph default
 module of the project for an example of a declarative model defintion).
 
\end_layout

\begin_layout Subsubsection
Supported dimension types
\end_layout

\begin_layout Itemize

\family typewriter
HexDimension
\family default
.
 This class supports discrete dimensions that are fixed-length byte arrays.
 In hbase composite keys they are translated into ASCII Hex representation
 of such for the sake of simpler readability when using tools like hbase
 shell.
 Hence, the name.
\begin_inset Newline newline
\end_inset

Typically, 
\family typewriter
HexDimension
\family default
 is suitable to represent uniformly-distributed hash IDs or otherwise hash-refer
enced data.
 It accepts java type 
\family typewriter
byte[]
\family default
 and its Pig equivalent (in context of compilation).
\end_layout

\begin_layout Itemize

\family typewriter
SimpleTimeHourHierarchy
\family default
.
 This is a hierarchical dimension to convert 
\family typewriter
GregorianCalendar
\family default
 and/or long values representing ms since epoch in fact streams into hierarchica
l descrete type [ALL].[YEAR-MONTH].[DATE-HOUR].
 I.e.
 the lowest bucket granularity for time series data is 1 hour.
 The continuous member data type for this dimension (when not expressed
 with a hierarchy member) is 
\family typewriter
GregorianCalendar
\family default
, or 
\family typewriter
Long
\family default
 expressing number of milliseconds since epoch (in context of projection
 compilation in pig).
\end_layout

\begin_layout Subsubsection
Supported measure types
\end_layout

\begin_layout Standard
The only types currently supported for the measures in the fact stream are
 double and long.
 
\end_layout

\begin_layout Subsection
Incremental cube compilation
\end_layout

\begin_layout Standard
Cube compilation is done via incremental Pig script dynamically generated
 by compilter component (see sample module for example of the compilation).
 With the current approach, compiler doesn't support any input adapters,
 so it cannot read any standard fact stream sources on its own.
 Instead, it relies on a fragment of the script that reads input into a
 predefined Pig relation, to be supplied.
 This Pig-scripted fragment is called 
\begin_inset Quotes eld
\end_inset

preambula
\begin_inset Quotes erd
\end_inset

 and expected to be supplied via Spring Resource specification.
 
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
Perhaps this only dependency on Spring is bad and it is worth considering
 getting rid of this abstraction; but developing a project-specific resource
 abstraction is probably just as equally bad.
\end_layout

\end_inset

 The compiler expects fact stream to be put in a predefined Pig relation
 (HBL_INPUT by default).
 
\end_layout

\begin_layout Standard
The requirements for HBL_INPUT relation produced by preambula is as follows:
 
\end_layout

\begin_layout Itemize
It must have all defined dimensions.
 Dimension names used must be the same as in model description.
 Dimension Pig types depend on the dimension class.
\end_layout

\begin_layout Itemize
It must have at least one measure fact (currently, of either long or double
 type only).
 The measure is recognized by having the same name as in model description.
 The scope of measures may be reduced by using exclude/include api on the
 compiler bean (see sample module for an example).
 By default, all measures are expected.
 Using measure scope reduction allows to easily compile in multiple fact
 streams containing different measures and potentially originating in different
 sources (for as long as all dimensions can be inferred for each of them).
 
\end_layout

\begin_layout Subsection
Query API
\end_layout

\begin_layout Standard
TODO
\end_layout

\begin_layout Subsubsection
Supported aggregate functions at this time.
\end_layout

\begin_layout Itemize
SUM()
\end_layout

\begin_layout Itemize
COUNT()
\end_layout

\begin_layout Subsection
Querying with a prepared query 
\end_layout

\begin_layout Standard
See the example for how to prepare and use query.
 It is recommended to use prepared query repeatedly to save on parsing it
 into an AST tree.
 (After all, that's what prepared queries are for).
\end_layout

\begin_layout Standard
Approximate current query syntax is (see RFC-822 for the BNF syntax used):
 
\end_layout

\begin_layout Standard

\family typewriter
\begin_inset Box Boxed
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout

\family typewriter
'select' select-expr *(',' select-expr) 'from' cube-name [where-clause]
 [group-clause]
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Plain Layout

\family typewriter
select-expr = measure-name / aggr-function [ 'as' alias-name ]
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Plain Layout

\family typewriter
aggregate-function = function-name '(' measure-name ')'
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Plain Layout

\family typewriter
where-clause = 'where' slice-spec *(',' slice-spec)
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Plain Layout

\family typewriter
slice-spec = dimension-name 'in' ('[' / '(') value / '?' [ ',' ( value /
 '?' ) ] (']' / ')')
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Plain Layout

\family typewriter
group-clause = 'group by' dimension-name *(, dimension-name)
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Plain Layout

\family typewriter
measure-name = ID / '?' ; id rules or substitution via a parameter
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Plain Layout

\family typewriter
cube-name = ID / '?' ; id rules or substitution via a parameter
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Plain Layout

\family typewriter
alias-name = ID / '?' ; id rules or substitution via a parameter
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Plain Layout

\family typewriter
function-name = ID / '?' ; id rules or substitution via a parameter
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Plain Layout

\family typewriter
dimension-name = ID / '?' ; id rules or substitution via a parameter
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Plain Layout

\family typewriter
value = ( '
\backslash
'' LITERAL '
\backslash
'' ) / LONG / DOUBLE
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Example:
\end_layout

\begin_layout Standard
\begin_inset Box Boxed
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout

\family typewriter
select d1 as dim1, COUNT( m1 ) from Example where d1 in [?], time in [?,?)
 group by d1
\end_layout

\end_inset


\end_layout

\begin_layout Standard

\emph on
Where-clause 
\emph default
is essentially a slice specification.
 Hence specification is imposed on a dimension using opened or closed interval
 syntax.
 E.g.
 [1,3) is a so-called half-open interval which includes between values of
 1 (including) and 3 (excluding).
 The limitation of the 
\emph on
where-clause 
\emph default
is that currently one cannot specify more than one slice specification for
 the same dimension.
 Semantic result of an attempt to specify multiple slices for the same dimension
 is currently undefined.
 
\end_layout

\begin_layout Standard
Aggregating over multidimensional hyperplane (a plane perpendicular to an
 axis and going thru a specific point on that axis) is hence equivalent
 to specifying '
\family typewriter
where dimension in [?]
\family default
'.
\end_layout

\begin_layout Paragraph
Query limitations.
\end_layout

\begin_layout Itemize
There has to be a cuboid specifying all dimensions in a group clause in
 the leftmost positions.
\end_layout

\begin_layout Itemize
Complement scan optimizations for hierarchies is not implemented in this
 release (only in our prototype).
\end_layout

\begin_layout Itemize
There's currently no way to run some useful analytic queries like 'select
 COUNT(fact), ip group by ip having COUNT(fact) > 10000'.
 
\end_layout

\begin_layout Section
TODOs and FIXMEs
\end_layout

\begin_layout Standard
At this point there's no JDBC provider available (we don't use jdbc; we
 integrate custom datasources directly into our reporting tool.
 Therefore, creating jdbc support ranked very low on our roadmap, but assuming
 there's an external interest in this, it should be an easy enhancement,
 all components are already there for it).
\end_layout

\begin_layout Standard
Complement scan optimizations for hierarchies are not in yet.
 (but there's a working prototype).
 
\end_layout

\begin_layout Standard
Poor selection of aggregate functions
\end_layout

\begin_layout Standard
Poor selection of hierarchy and dimension types
\end_layout

\begin_layout Standard
Poor selection of measure types
\end_layout

\begin_layout Standard
Is there a clever way of supporting some of HAVING conditions?
\end_layout

\end_body
\end_document
